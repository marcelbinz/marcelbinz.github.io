<!doctype html>
<html>
  <head>
    <meta name="google-site-verification" content="1HwYSbAUbchxLnyO80icFogMyUvcYKPxMCdocn6P3xM" />
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title> Marcel Binz</title>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Marcel Binz</h1>
        <img src="imgs/marcel.jpg" width="182" height="182" alt="Marcel Binz"> <span style="vertical-align:-20%"> </span><br>
        <a href="mailto:marcel.binz@helmholtz-munich.de"><img src="imgs/icons8-email-96.png" alt="mail" style="width:41.5px;height:41.5px;"></a>
        <span style="display:inline-block; width: 0px;"></span>
        <a href="https://scholar.google.com/citations?user=Lvm9Q8QAAAAJ&hl=en"><img src="imgs/icons8-google-scholar-150.png" alt="mail" style="width:41.5px;height:41.5px;"></a>
        <span style="display:inline-block; width: 0px;"></span>
        <a href="https://github.com/marcelbinz"><img src="imgs/icons8-github-120.png" alt="mail" style="width:41.5px;height:41.5px;"></a>
        <span style="display:inline-block; width: 0px;"></span>
        <a href="imgs/cv.pdf"><img src="imgs/icons8-cv-100.png" alt="mail" style="width:41.5px;height:41.5px;"></a> <br>

      </header>
      <section>

        <h1>About Me</h1>

        <p>I am a research scientist and deputy head of the <a href="http://hcai-munich.com/">Institute for Human-Centered AI</a> at Helmholtz Munich. <span style="vertical-align:-50%"> </span><br> My research employs computational models to uncover the fundamental principles behind human cognition. I believe that for a more complete understanding of human cognition, we must consider the human mind as a whole. My current goal is therefore to establish foundation models of human cognition â€“ models that cannot only simulate, predict, and explain human behavior in a single domain but those that offer a unified take on our mind. To accomplish this, I use tools such as neural networks, Bayesian inference, meta-learning, information theory, and large language models.</p>

        <h1>News</h1>



        <b>October 2024:</b>
        <ul style="margin-bottom:0px;">
          <li>New preprint: <a href="https://arxiv.org/abs/2410.01280">Sparse Autoencoders Reveal Temporal Difference Learning in Large Language Models</a>.</li>
        </ul>

        <b>September 2024:</b>
        <ul style="margin-bottom:0px;">
          <li><a href="imgs/Meta-learned_models_of_cognition.pdf">The commentaries and our response</a> for our BBS paper are now available.</li>
        </ul>

        <b>August 2024:</b>
        <ul style="margin-bottom:0px;">
          <li><a href="https://link.springer.com/article/10.3758/s13428-024-02455-8">A tutorial on open-source large language models for behavioral science</a> now accepted at Behavior Research Methods.</li>
        </ul>

        <b>July 2024:</b>
        <ul style="margin-bottom:0px;">
          <li>We are organizing a workshop on <a href="https://jacquespesnot.github.io/2024_CogSci_Workshop/">In-context learning in natural and artificial intelligence</a> at CogSci 2024 (Rotterdam). </li>
        </ul>

        <b>May 2024:</b>
        <ul style="margin-bottom:0px;">
          <li>Three papers accepted at ICML [<a href="https://arxiv.org/abs/2402.18225">1</a>, <a href="https://arxiv.org/abs/2402.01821">2</a>, <a href="https://arxiv.org/abs/2402.03969">3</a>]. </li>
          <li>I will be at ICLR in Vienna presenting our work on <a href="https://openreview.net/forum?id=eiC4BKypf1">Turning large language models into cognitive models</a>. </li>
        </ul>

        <b>March 2024:</b>
        <ul style="margin-bottom:0px;">
          <li>New preprint: <a href="https://arxiv.org/abs/2402.18225">CogBench: a large language model walks into a psychology lab</a>.</li>
        </ul>

        <b>February 2024:</b>
        <ul style="margin-bottom:0px;">
          <li>Two new preprints: <a href="https://arxiv.org/abs/2402.01821">Ecologically rational meta-learned inference explains human category learning</a> and <a href="https://arxiv.org/abs/2402.03969">In-context learning agents are asymmetric belief updaters</a>.</li>
        </ul>

        <b>January 2024:</b>
        <ul style="margin-bottom:0px;">
          <li><a href="https://openreview.net/forum?id=eiC4BKypf1">Turning large language models into cognitive models</a> got accepted at ICLR with ratings of 8, 8, 8, 8.</li>
        </ul>

        <b>December 2023:</b>
        <ul style="margin-bottom:0px;">
          <li>I moved to Munich.</li>
          <li>Two new preprints: <a href="https://arxiv.org/abs/2312.03759">How should the advent of large language models affect the practice of science?</a> and  <a href="https://osf.io/preprints/psyarxiv/f7stn">A tutorial on open-source large language models for behavioral science</a>.</li>
          <li>Two papers presented at NeurIPS: <a href="https://arxiv.org/abs/2305.17109">Reinforcement Learning with Simple Sequence Priors</a> and <a href="https://arxiv.org/abs/2305.12907">Meta-in-context learning in large language models</a>.</li>
        </ul>

        <b>November 2023:</b>
        <ul>
          <li><a href="https://arxiv.org/abs/2304.06729/">Meta-Learned Models of Cognition</a> got accepted at BBS. </li>
        </ul>

        <h1>Key Publications</h1>

        <b>Binz, M.</b>, & Schulz, E. (2024).  <a href="https://openreview.net/forum?id=eiC4BKypf1">Turning large language models into cognitive models</a>. International Conference on Learning Representations (ICLR). <span style="vertical-align:-50%"> </span><br>

        <b>Binz, M.</b>, Dasgupta, I., Jagadish, A., Botvinick, M., Wang, J.X., & Schulz, E. (2024).  <a href="https://arxiv.org/abs/2304.06729/">Meta-Learned Models of Cognition</a>. Behavioral and Brain Sciences. <span style="vertical-align:-50%"> </span><br>

        <b>Binz, M.</b>, & Schulz, E. (2023).  <a href="https://www.pnas.org/doi/10.1073/pnas.2218523120/">Using cognitive psychology to understand GPT-3</a>. Proceedings of the National Academy of Sciences. <span style="vertical-align:-50%"> </span><br>

        <b>Binz, M.</b>, & Schulz, E. (2022).  <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/cde542f47c67907e170a1e1a7b32f6ad-Abstract-Conference.html">Modeling Human Exploration Through Resource-Rational Reinforcement Learning</a>. 36th Conference on Neural Information Processing Systems (NeurIPS). Selected as Oral. <span style="vertical-align:-50%"> </span><br>

        <b>Binz, M.</b>, Gershman, S.J., Schulz, E., & Endres, D. (2022).  <a href="https://psycnet.apa.org/record/2022-18493-001?doi=1">Heuristics From Bounded Meta-Learned Inference</a>. Psychological Review. <br><br>

      </section>
      <footer>

        <p><small>Theme by <a href="https://github.com/orderedlist">orderedlist</a>.</small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
