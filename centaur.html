<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Centaur</title>
    <link rel="stylesheet" href="stylesheets/centaur_styles.css">
	<link rel="icon" href="imgs/centaur.png" type="image/x-icon">
</head>
<body>

    <!-- Header with Background Image -->
    <header>
	<div class="header-corner-text">Logo credits: Milena Rmus</div>
    </header>

    <!-- Main Content -->
    <main>
        <section>
            <h2>A foundation model to predict and capture human cognition</h2>
            <p>Establishing a unified theory of cognition has been a major goal of psychology. While there have been previous attempts to instantiate such theories by building computational models, we currently do not have one model that captures the human mind in its entirety. A first step in this direction is to create a model that can predict human behavior in a wide range of settings. Here we introduce Centaur, a computational model that can predict and simulate human behavior in any experiment expressible in natural language. We derived Centaur by finetuning a state-of-the-art language model on a novel, large-scale data set called Psych-101. Psych-101 reaches an unprecedented scale, covering trial-by-trial data from over 60,000 participants performing over 10,000,000 choices in 160 experiments. Centaur not only captures the behavior of held-out participants better than existing cognitive models, but also generalizes to new cover stories, structural task modifications, and entirely new domains. Furthermore, we find that the model's internal representations become more aligned with human neural activity after finetuning. Taken together, our results demonstrate that it is possible to discover computational models that capture human behavior across a wide range of domains. We believe that such models provide tremendous potential for guiding the development of cognitive theories and present a case study to demonstrate this.</p>
                 <p> Contact: <a href= "mailto: marcel.binz@helmholtz-munich.de"> 
      Marcel Binz
   </a>  </p>
        </section>

        <section>
            <center>
            <div class="objective-images">
            <table style="border-collapse: collapse; text-align: center; width: 100%;">
		    <tr>
			<td> <a href="https://huggingface.co/marcelbinz/Llama-3.1-Centaur-70B-adapter" target="_blank">
                    <img src="imgs/huggingface.png" height="150" alt="HuggingFace">
                </a> </td>
			<td><a href="https://www.nature.com/articles/s41586-025-09215-4" target="_blank">
                    <img src="imgs/nature.png" height="170" alt="arXiv">
                </a></td>
			<td><a href="https://github.com/marcelbinz/Llama-3.1-Centaur-70B" target="_blank">
                    <img src="imgs/github.png" height="150" alt="GitHub">
                </a></td>
		    </tr>
		    <tr>
			<td><b>Model</b></td>
			<td><b>Paper</b></td>
			<td><b>Code</b></td>
		    </tr>
	   </table>
            	 
            </div>
            </center>
        </section>

        <section>
	    <h2 id="use-centaur-title" style="display: inline-flex; align-items: center;">
		How to use Centaur?
	    </h2>
	    <ol>
		<li>Have access to at least one 80 GB GPU (e.g. A100)? You can run the model <a href= "https://github.com/marcelbinz/Llama-3.1-Centaur-70B/blob/main/run_minimal.py"> locally using unsloth</a>.</li>
		<li>Have neither GPUs nor money? You can explore a smaller version on <a href= "https://colab.research.google.com/drive/1BfVE7xRQePDBHZzk_3WOQPgfGs23BTly?usp=sharing"> Google Colab's free GPUs</a> or the larger model via our <a href= "https://huggingface.co/spaces/marcelbinz/Centaur"> Hugging Face Space</a>.</li>
	    </ol>
	</section>
		

	<section>
	    <h2 id="prompt-centaur-title" style="display: inline-flex; align-items: center;">
		How to prompt Centaur?
	    </h2>
	    <ol>
		<li>You can find prompt examples <a href= "https://github.com/marcelbinz/Llama-3.1-Centaur-70B/blob/main/run_minimal.py"> here</a> or in the <a href= "https://arxiv.org/abs/2410.20268"> Appendix of our preprint</a>. </li>
		<li>We did not employ a particular prompt template â€“ just phrase everything in natural language.</li>
		<li>Human choices are encapsulated by "<<" and ">>" tokens.</li>
		<li>Most experiments in the training data are framed in terms of button presses. If possible, it is recommended to use that style.</li>
	    </ol>
	</section>
		
      

	
	

    </main>

</body>
</html>

